Node :

Java Script modularity;
.......................

How to create modular application in javascript?

com.ibm.app.Hello.java 
 com/ibm/app/Hello.java
 com/ibm/app/Hello.class

javascript has no such fine grained modularity.

js is file based

hello.js, customer.js

js did not address how code can be shared across files.

 Javascript is file based modularity physically
 but logically there is no such modularity at language level.

 collection of variable declarations and function.

Once js started growing in large scale, dev struck to organize code.

2000, Smart developers started thinking about how to modualrize js code.
 

Module design patterns came.

1.Namespace design pattern : 2000 : jquery
2.AMD -Async Module Defintion : dojo
---------------------------------------------------------
3.CJS - Common JS =  namespace + amd
4.ES 6 Module design pattern  = amd + cjs
------------------------------------------------------------
5.System = AMD = CJS + ES 6
6.UMD = NAMESPACE + AMD + CJS = ES 6


only two design patterns are used in development

1.CJS - Common JS =  namespace + amd
2.ES 6 Module design pattern  = amd + cjs

CJS ; implemented inside node js. node supports commonjs by default.

I can organize the code , based on these patterns, but what about runtimes?
  js runtime never suppport these patterns directly then each design pattern is lib.

 Loaders : it is simple js lib to help link and load js files.
/////////////////////////////////////////////////////////////////////////////////////////////////////


lets start cjs first;
......................

cjs is built in node js.
node supports cjs in built. no separate loader or linker is required
but if you run cjs code on browsers , we need loaders.


Common js:

1.How to share code
  exports
  module.exports

2.How to link files
  require()


lab:

use case how to link files;

common js provides an api called "require(fileName)"
 -it is in built function provided by node
 -require function takes file name as parameter without .js extension.
 -require function  return value.


eg:
  function require(fileName){
    ......
   return somevalue;
 }

How to share code?

code could be

-variable declaration having any literals(strings,numbers,booleans,objects,functions...)
-function declaration
-class declaration


code can be shared in cjs via two containers.

exports
module.exports.

what is exports?

"exports" is just a variable.
"exports" variable is implemented inside require() function

function require(fileName){
   let exports={};
    ......
   return exports;
 }
exports value by default is empty literal object.
let res=require('./fileName');
res ==== {}
'


function require(fileName){
   let exports={};
   exports.greet = 'Hello'
    ......
   return exports;
 }

index.js
//. - current dir, mylib is js file to be linked
// let res = require('./mylib')

// console.log(res)
// console.log(res.greet)
// console.log(res.name)
// console.log(res.isActive)
const { greet, name, isActive, skills, score, sayHai, address } = require('./mylib')
const { log } = console;
log(greet)
log(name)
log(isActive)
log(skills)
log(score);
log(sayHai())
log(address.city)


src/mylib.js

//object augmentation on exports variable
exports.greet = 'Hello'
exports.name = 'Subramanian'
exports.isActive = true;
exports.score = 10;
exports.sayHai = function () {
    return 'Hai';
}
exports.address = {
    city: 'coimbatore'
}
exports.skills = ['java', 'javascript', 'node', 'microservices']

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
module.exports

-similar to exports
-dont pack code inside literal object
-it returns code as it is
 if code is function, it returns function.
 if code is variable , it returns variable


function require(fileName){
   let message='hello'

   //if exports ----use literal object
   else
   module.exports =message;

   return module.exports   
}

-exports can return mulitple items at the same time
-module.exports can return only one thing at the time.


module.exports is usefull

 -to return classes
 -to return functions
 -to return arrays
 -to return objects

any thing but only one.


const OrderService = require('./OrderService');

console.log(OrderService)
let { findAll } = new OrderService();
console.log(findAll())

class OrderService {
    constructor() {
        console.log('Order service is being intialized')
    }
    findAll() {
        return 'findAll'
    }
    save(order) {
        console.log(order);
        return 'save'
    }
}
module.exports = OrderService;
//////////////////////////////////////////////////////////////////////////////////////////////////////

How to return objects using module.exports? 
How to return from sub dir

src/services
src/data
src/apis
//way -1
// const PRODUCTS = [
//     {
//         id: 1,
//         qty: 10,
//         price: 100
//     },
//     {
//         id: 2,
//         qty: 20,
//         price: 600
//     }
// ];
// module.exports = PRODUCTS;

//way-2
module.exports = [
    {
        id: 1,
        qty: 10,
        price: 100
    },
    {
        id: 2,
        qty: 20,
        price: 600
    }
];

const PRODUCTS = require('../mock-data/products')

class ProductService {
    constructor() {
        console.log('Product Service is being intialized')
    }
    findAll() {
        return PRODUCTS;
    }
    save() {
        return 'save'
    }
}
module.exports = new ProductService();

const { findAll, save } = require('./services/ProductService');

const {log} = console;

findAll().forEach(product => console.log(product));
findAll().forEach(product => log(product));
//looks like java method refence syntax.
findAll().forEach(log);
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Lab:

Build  TODO Application using commonjs

-list of todos -array
-add new todo
-update existing todo
-remove completed todo
-findtodo by status- completed,ongoing

application should be modular, you can you use mock data of your choice.
////////////////////////////////////////////////////////////////////////////////////////////////////////

Blocking IO And Non blocking IO:   Sync and Async Programming
..............................................................



Blocking IO:

Input/output (IO) refers to interaction with devices such as a hard drive, network or database. 

Generally anything that is not happening in the CPU is called IO.

When you call an API that requests data from IO, you will not get a response instantly, but with some delay. This delay can be very small for requesting a file on a hard drive, and much longer when requesting data from a network. 

This is because the data you request from IO devices has to travel longer to the caller. For instance:
A file stored on a hard drive must be transferred through SATA cables and main board buses to the CPU

The data from a network resource located on a server far away must travel through network cables, routers and eventually the network interface card (NIC) in your computer to the CPU.

///////////////////////////////////////////////////////////////////////////////////////////////////////


Calling an API that requests data from IO will cause the running thread to “block”, i.e. 

it is waiting until the requested data has returned to the caller.

When a thread is blocked in Linux, it will be put in a Sleep state by the kernel until data has returned to the caller

Threads in sleep state immediately give up its access to the CPU, so to not waste CPU time.


After IO is ready, the thread is taken out of the Sleep state and put in Runnable state.

Threads in this state are eligible to be executed on the CPU again.

The thread scheduler will put the thread on a CPU when one is available. 

The process of taking threads on and off the CPU is called context switching.

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Why non-blocking IO?

The main benefit of non-blocking IO is that we need "less threads" to handle the same amount of IO requests.

When multiple calls to IO are done using blocking IO, for each call a new thread is created. 

A thread costs around 1MB, and there are some costs due to context switching. 

If you have a web server that handles 50k connections per second,

a thread per connection can be quite expensive.


Types of blocking
  There are actually two types of thread blocking:

1.CPU-bound blocking
2.IO-bound blocking

CPU-bound blocking
In this case the thread gets blocked because of some CPU intensive task it performs takes more time than “instantly”. 

For example when generating a bunch of prime numbers or rendering a 3d model. With CPU-bound blocking the thread is blocked because it’s actively being executed on the processor.


IO-bound blocking

Here, the thread gets blocked because it has to wait for data to return from an IO source, such as a network or a hard drive. 

The kernel will notice that there is no data available from IO and will therefore put the thread in some “sleep” state. Hence, with IO-bound blocking the thread is not¹ actively being executed on the processor.


Non-blocking IO

APIs that use blocking IO will block the thread until data from IO has returned.

 So what happens when you call a non-blocking API? Very well, it returns instantly and will not block the thread. 

This means the thread can immediately continue executing the code that comes after calling the API.

When data has returned from IO, the caller will be notified that the data is ready. 

This is generally done with a callback function that has access to the returned data.


Network IO and sockets:

To understand how non-blocking IO works under the hood we first need some understanding of how IO works at low level. 

A common use case for non-blocking IO is network IO, so it is best explained in this context. 


At kernel level a socket is used as an abstraction to communicate with a NIC.

Socket is entry and exit point of data transmission from hardware to os



At kernel level a socket is used as an abstraction to communicate with a NIC.

Socket is entry and exit point of data transmission from hardware to os


 This socket takes care of reading and writing data to/from the NIC, which in turn sends the data over the UTP cable on its way to the internet. 

For example, if you go to a URL in your browser; at low level the data in your HTTP request is written to a socket using the send(2) system call. 

When a response is returned, the response data can be read from that socket using the recv(2) 
 system call.
 The important thing to understand here is that when data has returned from network IO, it is ready to be read from the socket.
////////////////////////////////////////////////////////////////////////////////////////////////////////

Blocking are implemented at os level using os socket apis.
 eg : send and recv ------->are blocking apis

if any language uses these api as sys call under hood , those api are blocking apis

if you take java

 readFile()---------send()------>socket-------|

///////////////////////////////////////////////////////////////////////////////////////////////////////

Non blocking apis are provided by os only.Where pl just call those apis
........................................................................

flow:

Request1- application----select--------|kernal adds fd0 to watchlist -----devices
  <------------------------------------------------------------

Request2- application----select--------|kernal adds fd1 to watchlist ---device

Request3- application----select--------|kernal adds fd2 to watchlist --------device




Most non-blocking frameworks use an infinite loop that constantly checks (polls) if data is returned from IO.

This is often called the event loop. 

An event loop is literally a while(true) loop that in each iteration will check if data is ready to read from a network socket. 

Technically, sockets are implemented as file descriptors (FD) on UNIX systems.

It is therefore better to say that a FD is checked for ready data. 

The list of FDs that you want to check for ready data is generally called the interest list.


Operatings systems provide event loop construct for making non blocking io:


Let’s zoom a bit in on the event loop:
......................................

 Each (major) operating system provides kernel level APIs to help create an event loop.

In Linux there is epoll or io_uring,
BSD uses kqueue 
Windows has IOCP.
Each of these APIs is able to check FDs for ready data with a computational complexity of around.
/////////////////////////////////////////////////////////////////////////////////////////////////////////

What is Node.js?

Node.js is a platform to build non blocking io(async io) applications using javascript.

Node.js was created to build javascript server side io / network io applications.

History node.js:

node.js was inspired from nginx webserver(which is nonblocking httpserver).

node.js built on google v8 javascript engine.

Ryan Dhal who created node.js who decided to provide network io/fs io apis on js language.

Ryan Dhal who provided extra api for io operations inside js language , since js already supports non blocking features.
///////////////////////////////////////////////////////////////////////////////////////////////////////

How node.js bridges non blocking io with os?

with help of libuv.


libuv:

It is platform abstraction lib

libuv is a multi-platform support library with a focus on asynchronous I/O.

Components of node.js
......................

1.v8 - to run javascript 
2.libuv - multi platform io event loop abstraction lib.


Points:

1.application code is written using js 
2.js high level apis is mapped with javascript apis
3.js code is mapped with libuv and other libs with help of "C++"
4.other apis like openssl are provided as a lib which bound with high level javascript api.

///////////////////////////////////////////////////////////////////////////////////////////////////////

How nodjs implements async io notification and how it respond , how data we get it?

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Non blocking implementation:

non blocking apis are event driven,handler based,bound with low level apis.

non blocking apis are provided by node and libvu,os

console.log is not non blocking api.

how to know?

refer node.js doc

classification of non blocking api

1.timers
2.io apis
   file system
   network io
     -tcp,http.......

javascript provides way(styles) of writing nonblocking
.......................................................

1.callback style - this is core
2.promise style - abstraction of callbacks
3.async ....await style


callback /handlers : 
-function, 
-can take args,return values
-function is passed as parameter to non blocking apis : Registration.
  function is registered for notification for events with high level async apis.

1.timers :

settimeout
setinterval

//non blocking apis

//blocking api
const hi = () => console.log('hai')

const sayHello = handler => {
    //non blocking api ;timer 
    //register a with timer event within event queue
    setTimeout(handler, 5000);
};
hi();
sayHello(() => {
    console.log('hey , how are you?')
});
sayHello(() => {
    console.log('hey , how are you?')
});
hi();
///////////////////////////////////////////////////////////////////////////////////////////////////////


//data return in async ways

const { log } = console;

const delay = handler => {
    //once timeout return data back to callback function
    let fakeUser = {
        id: 1,
        name: 'admin'
    };
    //syntax -1
    // setTimeout(handler, 5000, fakeUser)
    //syntax-2
    setTimeout(() => {
        log('timeout happens')
        handler(fakeUser)
    }, 5000)
};
delay((fakeUser) => console.log(fakeUser))
delay(fakeUser => log(fakeUser))
delay(log);


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


//emit timer event periodically 
const { log } = console;
const hearBeat = hanlder => {
    let timerId = setInterval(hanlder, 1000, 'hello');
    setTimeout(() => {
        log('Stopping interval')
        clearInterval(timerId)
    }, 5000)

};

function start() {
    hearBeat(now => log(now));
}
start();
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

callback chaining, nested callbacks:
.....................................

The output of one callback will be input to another callback.

//async composition; callback nesting;the out put of one callback will be input to next on

//any biz logic have two things; success, failure.
//two callbacks- one for success and another for failure
//resolve-success, reject-failures
const { log } = console;

const getUser = (resolve, reject) => {
    //biz logic
    let fakeUser = {
        id: 2,
        name: 'admin'
    }
    //fakeUser = null;
    let errors = 'User not found'
    if (fakeUser) {
        setTimeout(resolve, 100, fakeUser)
    } else {
        setTimeout(reject, 100, errors)
    }
};

const login = (user, resolve, reject) => {
    let status = 'Login Successful';
    let errors = 'Login failed';
    if (user.name === 'admin') {
        setTimeout(resolve, 100, status)
    }
    else {
        setTimeout(reject, 100, errors)
    }
};

const showPage = (status, resolve, reject) => {
    let spage = 'You are admin';
    let fpage = 'You are guest';
    if (status === 'Login Successful') {
        setTimeout(resolve, 100, spage)
    }
    else {
        setTimeout(reject, 100, fpage)
    }
};



function startApp() {

    getUser(fakeUser => {
        log('getuser is called')
        //log(fakeUser);
        login(fakeUser, response => {
            log('login method is called!!');
            showPage(response, spage => {
                log('show page is called');
                log(spage)
            }, fpage => log(fpage))

        }, error => {
            log(error);
        })

    }, error => log(error))

}
startApp()

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
callback hell;
.............

  getUser(fakeUser => {
        log('getuser is called')
           login(fakeUser, response => {
            log('login method is called!!');
            showPage(response, spage => {
                log('show page is called');
                log(spage)
            }, fpage => log(fpage))

        }, error => {
            log(error);
        })

    }, error => log(error))

Questions:

1.Whether this is able to understand quickly
2.Whether this code is able to debug
3.Whehter this code is scalable?
4.whether this code is maintaiable?




  "No" : This is what we call as "Callback hell".

The way we write the code is called callback hell

fs.readdir(source, function (err, files) {
  if (err) {
    console.log('Error finding files: ' + err)
  } else {
    files.forEach(function (filename, fileIndex) {
      console.log(filename)
      gm(source + filename).size(function (err, values) {
        if (err) {
          console.log('Error identifying file size: ' + err)
        } else {
          console.log(filename + ' : ' + values)
          aspect = (values.width / values.height)
          widths.forEach(function (width, widthIndex) {
            height = Math.round(width / aspect)
            console.log('resizing ' + filename + 'to ' + height + 'x' + height)
            this.resize(width, height).write(dest + 'w' + width + '_' + filename, function(err) {
              if (err) console.log('Error writing file: ' + err)
            })
          }.bind(this))
        }
      })
    })
  }
})


callback hell is other wise called as doom of pyrbid.

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
///////////////////////////////////////////////////////////////////////////////////////////

How to write better callback programming /async/non blocking ? or How to avoid callback hell?



In 2005, JQUERY team started with working complex callback patterns, they found callback
hell problem.

They proposed a  Design pattern to write better callback programming(Async) programming.

  "Promise".

Promise is design pattern which hides complexity of callback patterns


SInce Promise is design pattern, many people have implemented Promise design pattern.

1.JQuery -first promise implementation
2.many libs and frameworks

2012 E6 Committee introduced promise design pattern  as  "Promise" Object  in javascript.


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Promises and non blocking,async and callback hell issues:
.........................................................

features of Promise Object:

1.Promise by deafult is Async. Which implements timer api with 0 ms .

Promise can be used with any async callback based implementations.



Promise Implemenation:

1. Create Promise Object from Promise contructor
2. Create Promise object from factory apis 

Promise object methods:
1.then - success
2.catch - errors
3.finally - clean up
4.resolve
5.reject
6.all
7.race




Lets code using Promise

Promise Object creations:

1.factory apis.
 resolve
 reject
 both

callback hell and promises:
..............................
//Promise Object creation, handle succcess and resolve.

const { log } = console;
//callback version
const sayHello = (callback) => setTimeout(callback, 1000, 'Hello!!!');
sayHello(response => log(response))
//promise version 
//promise does not take any callback as parameter
//results are captured by then and catch methods of Promise Object

const sayHai = () => {
    //send only success
    return Promise.resolve('Hello Promise');
};
const getError = () => {
    return Promise.reject('something went wrong')
}

///some biz logic
const validate = (userName = 'admin', password = 'admin') => {
    if (userName === 'admin' && password === 'admin') {
        return Promise.resolve('Login success')
    } else {
        return Promise.reject('Login failed')
    }
}


console.log('start')
// let mypromise = sayHai();
// mypromise.then(response=>log(response))
//builder pattern /fluent pattern; 

sayHai()
    .then(response => log(response)) //succces/resolve

getError()
    .then(response => log(response))
    .catch(error => log(error));

validate()
    .then(response => log(response))
    .catch(error => log(error));


validate('foo','foo')
    .then(response => log(response))
    .catch(error => log(error));

console.log('end')
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
//promise constructors ; Promise constructors are used to convert existing callback
//based programming

//new Promise(callbackfunction(res,reject){logic});

const { log } = console;

const validate = (userName = 'admin', password = 'admin') => {
    return new Promise((resolve, reject) => {
        if (userName === 'adminl̥' && password === 'admin') {
           //return status with promise , convert callback based into promise          
            setTimeout(resolve, 1000, 'Login Success')
        } else {
            setTimeout(reject, 1000, 'Login Failed')

        }
    });

}

function startApp() {
    validate()
        .then(log)
        .catch(log);
}
startApp();

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

const { log } = console;

const getUser = () => {
    //biz logic
    let fakeUser = {
        id: 2,
        name: 'admin'
    }
    //fakeUser = null;
    let errors = 'User not found'
    if (fakeUser) {
        return Promise.resolve(fakeUser);
    } else {
        return Promise.reject(errors);
    }
};

const login = user => {
    let status = 'Login Successful';
    let errors = 'Login failed';
    if (user.name === 'admin') {
        return Promise.resolve(status);
    }
    else {
        return Promise.reject(errors);
    }
};

const showPage = status => {
    let spage = 'You are admin';
    let fpage = 'You are guest';
    if (status === 'Login Successful') {
        return Promise.resolve(spage);
    }
    else {
        return Promise.reject(fpage);
    }
};



function startApp() {

    // getUser(fakeUser => {
    //     log('getuser is called')
    //     //log(fakeUser);
    //     login(fakeUser, response => {
    //         log('login method is called!!');
    //         showPage(response, spage => {
    //             log('show page is called');
    //             log(spage)
    //         }, fpage => log(fpage))

    //     }, error => {
    //         log(error);
    //     })

    // }, error => log(error))

    getUser()
        .then(user => {
            log('get user is called');
            //login
            login(user).then(status => {
                log('Login is called');
                //show page
                showPage(status).then(page => {
                    log('show page is called')
                    log(page)
                }).catch(err => log(err));

            }).catch(err => log(err));
        })
        .catch(error => {
            log(error)
        })
        .finally(() => log('done!!'));

    //simple version

    getUser().then(user => {
        log('get user is called');
        return login(user);
    }).then(status => {
        log('Login is called');
        return showPage(status)
    }).then(page => {
        log('show page is called')
        log(page);
    }).catch(error => {
        log(error)
    }).finally(() => log('done!!'));
    //single body ; only return
    getUser()
        .then(user => login(user))
        .then(status => showPage(status))
        .then(log)
        .catch(log)
        .finally(() => log('done!!'));

    getUser()
        .then(login)
        .then(showPage)
        .then(log)
        .catch(log)
        .finally(() => log('done!!'));


}
startApp()
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

async and await ; es 7 keywords


Promise Hell: Promise has limitions;
......................

1.Promise is still  complex when you start scalling complex async operations.

2.Which is not readable ,which uses lot of then, catch blocks

In order to write even simple complex async work flows ES 7 introduced
a concept called "async await" keywords


 It is simplest pattern of Promises.
 It is promise driven only.

         "Sync style of Async Code" 

async key must be used with function declaration.
await is used to pause async calls


getUser()
    .then(login)
    .then(log)
    .catch(log)
    .finally(() => console.log('login done'))


//async .... await keywords
//async key must be part of function declaration; async functions
//await key must be used for promise invocation;

const validate = (userName = 'admin', password = 'admin') => {
    if (userName === 'admin' && password === 'admin') {
        return Promise.resolve('Login success');

    } else {
        return Promise.reject('Login failed')
    }
}

async function startApp() {
    //promise version
    // validate()
    //     .then(res => console.log(res))
    //     .catch(err => console.log(err))
    //     .finally(() => console.log('done'))
    //async
    try {
        const res = await validate();
        console.log(res);
    }
    catch (err) {
        console.log('error')
    }
    finally {
        console.log('done!!!')
    }
}
startApp();
/////////////////////////////////////////////////////////////////////////////////
const { log } = console;

const getUser = () => {
    //biz logic
    let fakeUser = {
        id: 2,
        name: 'admin'
    }
    //fakeUser = null;
    let errors = 'User not found'
    if (fakeUser) {
        return Promise.resolve(fakeUser);
    } else {
        return Promise.reject(errors);
    }
};

const login = user => {
    let status = 'Login Successful';
    let errors = 'Login failed';
    if (user.name === 'admin') {
        return Promise.resolve(status);
    }
    else {
        return Promise.reject(errors);
    }
};

const showPage = status => {
    let spage = 'You are admin';
    let fpage = 'You are guest';
    if (status === 'Login Successful') {
        return Promise.resolve(spage);
    }
    else {
        return Promise.reject(fpage);
    }
};

const initApp = async () => {
    try {
        const user = await getUser();
        const status = await login(user);
        const page = await showPage(status);
        log(`${user.name} ${status} ${page}`)
    }
    catch (err) {
        console.log('error')
    }
    finally {
        console.log('done!!!')
    }
};
initApp();
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

const TODOS = require('../mock-data/todos');

class TodoService {

    //blocking version; 
    findAllBlocking() {
        return JSON.stringify(TODOS);
    }
    //non blocking version; callback based
    findAllNonBlockingCB(handler) {
        setTimeout(handler, 5000, JSON.stringify(TODOS));
    }
    //non blocking version; callback based
    findAllNonBlockingPromise() {
        return new Promise((resolve, reject) => {
            setTimeout(resolve, 5000, JSON.stringify(TODOS));
        });
    }


}
module.exports = new TodoService();

const { findAllBlocking, findAllNonBlockingCB, findAllNonBlockingPromise } = require('./services/TodoService');
const { log } = console;


async function startApp() {
    //call blocking version
    // const todos = findAllBlocking();
    // log(todos)
    //findAllNonBlockingCB(todos => log(todos));
    //promise 
    // findAllNonBlockingPromise()
    //     .then(todos => log(todos))
    //     .catch(err => log(err))
    //     .finally(() => log('done'))
    const todos = await findAllNonBlockingPromise();
    log(todos);

}
startApp();
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

node built in objects;

node supports all js objects- string,number,object,math,date,json,promise,array........

node does not support dom objects - window,document,history...

node can execute js code via 

->node REPL
 node
->node command

in browser window is super object
in node process is super object

node command;

node jsfile.js

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


Node and Modularity:
....................

node is highly modular platform, you can write modular applications
node by default supports cjs module system.

in node module is called "node module'


Types of modules:

1.Custom module
  Written you , eg: OrderController....
  exports,module.exports
2.in built modules
   Modules are supplied by node , which are supplied during node installation.
3.Third party modules
   provided by third parties, like frameworks,libs etc...




1.node in built modules

1.os module
2.events module
3.file system module
4.path
5.http module

os

//node built in modules; os module
const {cpus,arch} = require('os');

console.log('Total CPUs')
console.log(cpus());
console.log('Arch ',arch())

./ vs ''
.........

 require('./services/TODOService');
  ->here you can see ./
  ./ -current dir
 require('os'); => 
  -here no ./ 

Why?

Note : if you are java devp, you know the classpath , how it works?



require('os');

Node internally uses a search algorthim,node always looks the folder called
 "node_modules" in the current project, if not , then it searches, the node in built 
installtion folder---c:/pf/node/node_nodules--if it finds it will pick up from there else it will throw error.

require('./services/TODOService');
   it will lookup in the current dir or sub dirs only.


error if there is no module;


C:\session\ibm\Sep\nodejs-session\mynode-app>node src/index.js
internal/modules/cjs/loader.js:800
    throw err;
    ^

Error: Cannot find module 'osxx'
Require stack:
- C:\session\ibm\Sep\nodejs-session\mynode-app\src\index.js
[90m    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:797:15)[39m
[90m    at Function.Module._load (internal/modules/cjs/loader.js:690:27)[39m
[90m    at Module.require (internal/modules/cjs/loader.js:852:19)[39m
[90m    at require (internal/modules/cjs/helpers.js:74:18)[39m
    at Object.<anonymous> (C:\session\ibm\Sep\nodejs-session\mynode-app\src\index.js:2:21)
[90m    at Module._compile (internal/modules/cjs/loader.js:959:30)[39m
[90m    at Object.Module._extensions..js (internal/modules/cjs/loader.js:995:10)[39m
[90m    at Module.load (internal/modules/cjs/loader.js:815:32)[39m
[90m    at Function.Module._load (internal/modules/cjs/loader.js:727:14)[39m
[90m    at Function.Module.runMain (internal/modules/cjs/loader.js:1047:10)[39m {
  code: [32m'MODULE_NOT_FOUND'[39m,
  requireStack: [
    [32m'C:\\session\\ibm\\Sep\\nodejs-session\\mynode-app\\src\\index.js'[39m
  ]
}

C:\session\ibm\Sep\nodejs-session\mynode-app>
//////////////////////////////////////////////////////////////////////////////////////////////////////

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Event Emitter module;

how to build application event driven programming.

Much of the Node.js core API is built around an idiomatic asynchronous event-driven architecture in which certain kinds of objects (called "emitters") emit named events that cause Function objects ("listeners") to be called.


we register and listen for that.

We can build application events; we can make event driven apps.


const EventEmitter = require('events'); //return function;


//domain class
class OrderService extends EventEmitter {
    constructor() {
        super();
        //event registration
        this.on('order.created', data => {
            //process events async
            setTimeout(() => {
                console.log('order.created is being processed')
                console.log(data)
            }, 1000)
        });
    }
    //biz api
    placeOrder(order) {
        //async event driven arch
        setTimeout(() => {
            this.emit('order.created', order)
        }, 1000)
    }

}

function start() {

    const orderService = new OrderService();
    orderService.placeOrder({
        id: 1,
        qty: 100,
        price: 1000
    })

}
start();

///////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////

non blocking io:

Node non blocking io apis

1.fs io
   -files system 
2.network io
  -http : web apps
  -tcp
  -udp



Does node support blocking IO?

Blocking io means

  readFile----stackframe --read file

All blocking io operations are handled by libuv   worker pool threads.
 when you read, node will assign a thread  to read / write file.

Note:
1.Dont use blocking io apis for big files
2.Dont use blocking io apis in network applications.
3.Node supports only disk file io in blocking mode, not network apis


Blocking io dont have callbacks.


//how to read and write files in non blocking way.

const fs = require('fs');

let filePath = './src/assets/info.txt';
let config = {
    encoding: 'UTF-8'
};
console.log('start')
fs.readFile(filePath, config, (err, data) => {
    if (err) throw err;
    console.log(data);
});
console.log('endl̥')


//how to read and write files in non blocking way.

const fs = require('fs');

let filePath = './src/assets/info-copy.txt';
let config = {
    encoding: 'UTF-8'
};
console.log('start')
let data = 'Hello,How are you?'
fs.writeFile(filePath, data, config, (err) => {
    if (err) throw err;
    console.log('file has been written');
});
console.log('endl')



//blocking version.

//blocking io
const fs = require('fs');

const path = './src/assets/info.txt'
const Writepath = './src/assets/greetings.txt'

const options = {
    encoding: 'UTF-8'
}
console.log('start')
const fileContent = fs.readFileSync(path, options);
console.log(fileContent);
//write file
fs.writeFileSync(Writepath,"Hello!!",options);

console.log('end')

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Global Variables:

1.__dirname
      ->Get current dir path
2.__filename
     ->Get current dir + path__filename
     ->Get current dir + path


path module:
The path module provides utilities for working with file and directory paths.
it is platform independant way of accessing file paths and dirs.


//path module and __filename and __dirname
const fs = require('fs');
const path = require('path');
const filePath = path.join(__dirname, 'assets/info.txt')
const options = {
    encoding: 'UTF-8'
}
fs.readFile(filePath, options, (err, data) => {
    if (err) throw err;
    console.log(data);
});
///////////////////////////////////////////////////////////////////////////////////////////////////////

                                           Streaming
                                         ..............

Flow of data from one place to another place.

Types of IO Read and write

1.Non Streaming 

 The file which is loaded fully into node buffer and will be delivered to caller.

 This apporach is not good when we read and write concurrently.Node process may crash if no more memory
  
non streamings apis
 fs.readFile and fs.writeFile.

2.Streaming :

->data will be delivered chunk by chunk-(part by part)
->streaming enables continuous flow of data, so node buffer will not full.
->it is suitable for network delivery 
->In node most of network apis are by default streaming only.

Note :

 Streaming enable event driven io.
 Streaming apis are having lot of built in events.



Types of Streams:

1.Readable Stream : input
2.Writeable stream : output
3.Duplex stream : read + output


Built in readable Streams:

HTTP responses, on the client
HTTP requests, on the server
fs read streams
zlib streams
crypto streams
TCP sockets
child process stdout and stderr
process.stdin

Writable Streams:

HTTP requests, on the client
HTTP responses, on the server
fs write streams
zlib streams
crypto streams
TCP sockets
child process stdin
process.stdout, process.stderr

All streaming apis are powered with events
node io streams has built in events.
events are emitted by node.
Our programs are listeners

common events in all io

data event:
 which is emitted by node, for each chunk.

close event:
The 'close' event is emitted when the stream and any of its underlying resources (a file descriptor, for example) have been closed.

end event:
The 'end' event is emitted when there is no more data to be consumed from the stream.

Event: 'error'
 The 'error' event may be emitted by a Readable implementation at any time
Typically, this may occur if the underlying stream is unable to generate data due to an underlying internal failure, or when a stream implementation attempts to push an invalid chunk of data.


//file system stream;
const fs = require('fs')
const path = require('path');
const { log } = console;


const fileName = path.join(__dirname, 'assets/info.txt');
const config = {
    encoding: 'UTF-8'
}
//read stream
const inputStream = fs.createReadStream(fileName, config);
//data reterival you can do in two places; inside data event , or end event.
//register events
//data event
let data = '';
inputStream.on('data', chunk => {
    log(`Received ${chunk.length} bytes of data.`)
    //log(chunk);
    data += chunk;
});
inputStream.on('end', () => {
    log('There will be no more data to read!');
    log(data)
});
//error event: for error handling
inputStream.on('error', function (err) {
    log(`Some thing went wrong! ${err}`)
});

//how to implement write stream
const fs = require('fs');
const path = require('path');

const fileName = path.join(__dirname, 'assets/granis.txt');
const config = {
    encoding: 'utf8',
    flag: 'w'
};
const outputStream = fs.createWriteStream(fileName, config);

const grains = ['wheat', 'rice', 'oats'];

grains.forEach(item => {
    outputStream.write(item + "  ");
    console.log("Wrote: %s", item);
});

outputStream.close();

outputStream.on('close', () => {
    console.log('file has been closed ')
})
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
                                            Back Pressure
------------------------------------------------------------------------------------------------------


What is back pressure?

 Back Pressure is type of problem which occurs when we read and write data togther in stream mode.
 Back Pressure means inputstream is fast, outputstream slow, then data will be lost.

How to handle  Back pressure?

Handling back pressure:
.......................
Pause Input stream if the Node Process memory is full(Buffer),resume if buffer/process memory is empty.

stream.pause() if stream is full
else
stream.resume() if stream is drain


const fs = require('fs');
const path = require('path');

const inputfileName = path.join(__dirname, 'assets/big.file');
const outputfileName = path.join(__dirname, 'assets/big_copy.file');

const config = {
    encoding: 'UTF-8'
}

//Back pressure handling
const readerStream = fs.createReadStream(inputfileName, config);
const writeStr = fs.createWriteStream(outputfileName, config);


readerStream.on('data', function (chunk) {
    console.log(`Received ${chunk.length} bytes of data.`);
    /**
     * Returns: <boolean> false if the stream wishes for the calling code to
     *  wait for the 'drain' event to be emitted before continuing to 
     *  write additional data; otherwise true.
     */
    let buffer_good = writeStr.write(chunk);
    if (!buffer_good) readerStream.pause();
});
writeStr.on('drain', function () {
    console.log('buffer drained!');
    readerStream.resume();
});
readerStream.on('end', function () {
    //console.log(data);
});

readerStream.on('error', function (err) {
    console.log(err.stack);
});




///////////////////////////////////////////////////////////////////////////////////////////////////

pipe method is simplest method for implementing back pressure:


const fs = require('fs');
const path = require('path');

const inputfileName = path.join(__dirname, 'big.file');
const outputfileName = path.join(__dirname, 'big_copy.file');

const config = {
      encoding: 'UTF-8'
}

//Back pressure handling
const readerStream = fs.createReadStream(inputfileName, config);
const writeStr = fs.createWriteStream(outputfileName, config);

//backPressure streams
//pipe method is simplest method which wraps resume,pasuse,drain 
readerStream.pipe(writeStr);
////////////////////////////////////////////////////////////////////////////////////////////////////

const fs = require('fs');
const path = require('path');

const inputfileName = path.join(__dirname, 'assets/big.file');
const outputfileName = path.join(__dirname, 'assets/big_copy.file');

const config = {
      encoding: 'UTF-8'
}

//Back pressure handling
const readerStream = fs.createReadStream(inputfileName, config);
const writeStr = fs.createWriteStream(outputfileName, config);

//backPressure streams
//pipe method is simplest method which wraps resume,pasuse,drain 
readerStream.pipe(writeStr);
////////////////////////////////////////////////////////////////////////////////////////////////////////

Networking:
..........

Web application:non blocking http implementation;
..................................................

HTTP module is used to build http server,app, deployment


HTTP modules objects:
....................

Agent :
  client object
ClientRequest
   Request object is used to handle http client requests
Server
  Server object is used to implement http servers/web containers
ServerResponse
  Object is used to send data 
IncommingMessage
   Represents message payloads.

const http = require('http');


//create Server
const server = http.createServer((request, response) => {
    response.write('Hello');
    response.end();

})

//start the server
let port = 3001;
server.listen(port, () => {
    console.log('opened server on', server.address());
});

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

HTTP Events:
...........

const http = require('http');


//create Server
const server = http.createServer((request, response) => {
    response.write('Hello');
    response.end();
    //response events
    response.on('close', () => {
        console.log('response close event')
    })
    response.on('finish', () => {
        console.log('response finish event')
    })
})

//start the server
let port = 3001;
server.listen(port, () => {
    console.log('opened server on', server.address());
});
//attach and listen for server events
server.on('request', (request, response) => {
    console.log(`${request.url} - ${request.method} ${new Date()} `)
});

////////////////////////////////////////////////////////////////////////////////////////////////////////

HOW TO SEND JSON?


const http = require('http');
const { findAllNonBlockingPromise } = require('./services/TodoService');

//create Server
const server = http.createServer(async (request, response) => {
    response.writeHead(200, {
        'Content-Type': 'application/json'
    })
    const todos = await findAllNonBlockingPromise();
    response.write(todos);
    response.end();
    //response events
    response.on('close', () => {
        console.log('response close event')
    })
    response.on('finish', () => {
        console.log('response finish event')
    })
})

//start the server
let port = 3001;
server.listen(port, () => {
    console.log('opened server on', server.address());
});
//attach and listen for server events
server.on('request', (request, response) => {
    console.log(`${request.url} - ${request.method} ${new Date()} `)
});

////////////////////////////////////////////////////////////////////////////////////////////////////

const http = require('http');
//create Server
const server = http.createServer((request, response) => {

    //read data ; you have to attach an event called data.
    let data = '';
    request.on('data', chunk => {
        console.log(chunk.length);
        data += chunk;
    });
    request.on('end', () => {
        console.log(data);
        response.write(data);
        response.end();
    });

    //response events
    response.on('close', () => {
        console.log('response close event')
    })
    response.on('finish', () => {
        console.log('response finish event')
    })
})

//start the server
let port = 3001;
server.listen(port, () => {
    console.log('opened server on', server.address());
});
//attach and listen for server events
server.on('request', (request, response) => {
    console.log(`${request.url} - ${request.method} ${new Date()} `)
});

With Back pressure:
const http = require('http');
//create Server
const server = http.createServer((request, response) => {

    //read data ; you have to attach an event called data.
    // let data = '';
    // request.on('data', chunk => {
    //     console.log(chunk.length);
    //     data += chunk;
    // });
    // request.on('end', () => {
    //     console.log(data);
    //     response.write(data);
    //     response.end();
    // });
    request.pipe(response);

    //response events
    response.on('close', () => {
        console.log('response close event')
    })
    response.on('finish', () => {
        console.log('response finish event')
    })
})

//start the server
let port = 3001;
server.listen(port, () => {
    console.log('opened server on', server.address());
});
//attach and listen for server events
server.on('request', (request, response) => {
    console.log(`${request.url} - ${request.method} ${new Date()} `)
});
/////////////////////////////////////////////////////////////////////////////////////////////////////

Lab: 
You have file called info.txt. now you need to transfer this content to client via http.

Task:
-You need to create FileService class like TodoService
-you need to write a logic inside FileService with Promise
-you have to write a http code from where you have to call FileService api , then you have to send data
 to client.
//////////////////////////////////////////////////////////////////////////////////////////////////////

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

IS it possible to build real time web apps by using just pure http module alone?

 Yes! but it is very complex

How to build real time web applications?

-frameworks and libs.

How to work with frameworks? who provides frameworks ? how frameworks are distributed?

Frameworks and libs are not part of core node js. which is coming from third parties.

as node modules.

node modules types
1.custom module - discussed
2.in built modules - disucssed
3.third party modules - 


Third party modules :
 created by others , we are going to use them.
 like libs,frameworks....


Where is third moudles are located?
what if i want to share my module to other developers?


mvnrepository ==maven ==third party jar files

/////////////////////////////////////////////////////////////////////////////////////////////////////

node package manager; npm:
..........................

npm is tool is used to distribute node modules to others
and you can get node modules from other others.

npm tool is distributed along with node installation

npm uses public repository server called npmjs.com npmjs.org

tools and libs,frameworks all are distributed as node modules into repository.


Java script application :

Javascript Project Structure:(server side/ client side)
.........................................................

The project must have two things

1.package.json file :
   meta file which describes the project information
2.node_modules folder
   which contains libs/frameworks/tools code.


create package.json file

>npm init

{
  "name": "mynode-app",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC"
}
////////////////////////////////////////////////////////////////////////////////////////////////////////


npm is used

to install,uninstall,publish node modules from node repo / into node repo.

if you install third party modules , into your project, node distributes npm tool ,using this you can install,uninstall,upgrade node modules.


npm syntax:

npm commandName.

node_modules : folder which can hold all javascript modules downloaded from repo.


installing module:

>npm install  moduleName  --options
>npm i moduleName --options


>npm install module 
  here no option is told, means default is --save

>npm i module

options:
 --save ; 
 --save-dev
 -g
//////////////////////////////////////////////////////////////////////////////////////////////////////
App development ; three stage

1.dev
2.testing
3.production.

if you install any packages/dependencies, you can tell that is it for production and developemnt, only devel/testing

if you are installing any node module, you can tell, do you want to use only for development
or development + production.

Unit testing libs : Junit.jar===>java

 --save = >    development + production
 --save-dev => only for development

Which code need not be used for production:

1.All testing related  libs/frameworks - unit,e2s
2.Tools like compilers,frameworks related code.

Who will separate out this depedency(lib) for production/dev

 Build tools -  webpack.
 webpack will scan package.json---extracting prod depedencies

///////////////////////////////////////////////////////////////////////////////////////////

lab : install npm modules;
...........................
>npm install lodash --save 
>npm i lodash 


"dependencies": {
    "lodash": "^4.17.15"
  }

const array = require('lodash/array');

const list = [1, 2, 3];

array.fill(list, 'a');
console.log(list);

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
How to unit test javascript applications- serverside/clientside?

-we have frameworks,libs.... ; not necessary for production.


Unit testing Env:

->chai.js

npm install chai --save-dev

"devDependencies": {
    "chai": "^4.2.0"
  }

any thing inside this depdenencies will be used in dev only


npm install chai --save-dev

"devDependencies": {
    "chai": "^4.2.0"
  }

any thing inside this depdenencies will be used in dev only


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

how to uninstall any module?

npm unistall chai --save-dev

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&************************&&&&&&&&&&&&&&&&&&&&&&&&&&&&
-g : global dependencies:
..........................
global package : package will be installed globally 
 inside c drive.
 looks like exe/bat files in windows

global packages not used for development(coding)

tools
 ->build system
 ->servers - webservers,testing servers
 ->compilers : babel,tsc....

Tool:

Unit Testing Server:

Mocha -server
chai - for coding assertion lib


npm install --global mocha
npm install -g mocha

C:\Users\sasub\AppData\Roaming\npm\mocha

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Automation: scripts;
....................

We can automate js applications.

write all auotomation steps inside scripts

"scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  }

key: value

key is called command-script command
value is task to be executed. ; task could be any thing.


command can be built in or custom commands

npm provides lot of built in commands

start,test,postinstall,preinstall..........


how to run node apps using npm scripts.

node filename.js --direct use

via script
how to run script

>npm commandname ---incase of built in command
>npm start

>npm run commandname - custom commands
>npm run subu

  "scripts": {
    "test": "mocha",
    "start": "node src/app.js",
    "subu": "node src/app.js"
  },
///////////////////////////////////////////////////////////////////////////////////////////////////////

Node js Web frameworks:

1.express.js


express js is web application framework built on top of core http module.
express abstracts all low level pulmbing web application dev
express can be used to build web api(REST) and dynamic web applications.

Getting started:

>npm i express --save

express contains lot of objects.

1.Application 
2.Request
3.Response
4.Router

express provides a global function

function express(){

}
expression funciton returns application object when you call.

1.Application object

->container object which contains other objects
->Every express applicaiton must have one single application object.

How to create application object?

//require('express') returns a function-factory funciton used to create app
const express = require('express');

//call express variable having funciton to create app object
const app = express();

how to start server?
//start the server
app.listen(3001, () => {
    console.log('Express is ready!!')
})

how to handle req and response?

Core http moudule lacks URL AND METHOD Mapping.

GET    /api/resource
POST   /api/resource
PUT    /api/resource
DELETE /api/resource

Express core idea is to isloate request processing in fine grained way.

//require('express') returns a function-factory funciton used to create app
const express = require('express');

//call express variable having funciton to create app object
const app = express();

//request handling

app.get('/', (request, response) => {
    response.end('Home');
});
app.get('/api/message/hello', (request, response) => {
    response.end('hello');
});
app.get('/api/message/hai', (request, response) => {
    response.end('hai');
});
app.post('/api/message/hai', (request, response) => {
    response.end('post');
});
app.put('/api/message/hai', (request, response) => {
    response.end('put');
});
app.delete('/api/message/hai', (request, response) => {
    response.end('delete');
});
//start the server
app.listen(3001, () => {
    console.log('Express is ready!!')
})

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Modularizing express application

-based on domain(resource)- message,products,customers.
-folders ; each domain we may have separate folders
-files ; we have to write each resource inside file

//require('express') returns a function-factory funciton used to create app
const express = require('express');
const messageRouter = require('./routers/messagerouter');
const todosRouter = require('./routers/todosrouter');

//call express variable having funciton to create app object
const app = express();

//bind router with main application
app.use('/api/message',messageRouter);
app.use('/api/todos',todosRouter);

//request handling
app.get('/', (request, response) => {
    response.end('Home');
});

//start the server
app.listen(3001, () => {
    console.log('Express is ready!!')
})

const express = require('express')
const { findAllNonBlockingPromise } = require('../services/TodoService');
const router = express.Router();


//todos
router.get('/list', async (request, response) => {
    try {
        const todos = await findAllNonBlockingPromise();
        response.status(200).json(todos);
    }
    catch (err) {
        response.status(500).json(err)

    }
});
router.get('/:id', (request, response) => {
    response.end('hai');
});
router.post('/create', (request, response) => {
    response.end('post');
});
router.put('/update', (request, response) => {
    response.end('put');
});
router.delete('/remove', (request, response) => {
    response.end('delete');
});
module.exports = router;

const express = require('express')
const router = express.Router();

router.get('/hello', (request, response) => {
    response.end('hello');
});
router.get('/hai', (request, response) => {
    response.end('hai');
});
router.post('/hai', (request, response) => {
    response.end('post');
});
router.put('/hai', (request, response) => {
    response.end('put');
});
router.delete('/hai', (request, response) => {
    response.end('delete');
});

module.exports = router;
////////////////////////////////////////////////////////////////////////////////////////////////////////

Micro Services Implementation on Node JS:
.........................................

Distributed application.

app logic + infrastructure.
........................................................................................................

MicroServices:
  Microservice is archtecture of building distributed application.


Building applications into small applications, communicate them, exchange data,deploy them, maintain them.

How to start building micro services apps?

  dev  ----------- infra structure

micro services are ployglot - any language.


java
 -spring cloud
 -micro profile
 -Ecplise vertx

javascript:

Moleculer
   Progressive microservices framework for Node.js.



Moleculer features:

1.Promise-based solution (async/await compatible)
2.request-reply concept
3.support event driven architecture with balancing
4.built-in service registry & dynamic service discovery
5.load balanced requests & events (round-robin, random, cpu-usage, latency, sharding)
6.many fault tolerance features (Circuit Breaker, Bulkhead, Retry, Timeout, Fallback)
7.plugin/middleware system
8.support versioned services
9.support Streams
10.service mixins
11.built-in caching solution (Memory, MemoryLRU, Redis)
12.pluggable loggers (Console, File, Pino, Bunyan, Winston, Debug, Datadog, Log4js)
13.pluggable transporters (TCP, NATS, MQTT, Redis, NATS Streaming, Kafka, AMQP 0.9, AMQP 1.0)
14.pluggable serializers (JSON, Avro, MsgPack, Protocol Buffer, Thrift)
15.pluggable parameter validator
16.multiple services on a node/server
17.master-less architecture, all nodes are equal
18.parameter validation with fastest-validator
19.built-in metrics feature with reporters (Console, CSV, Datadog, Event, Prometheus, StatsD)
20.built-in tracing feature with exporters (Console, Datadog, Event, Jaeger, Zipkin)
21.official API gateway, Database access and many other modules…


Moleculer setup:

project creations;

1.from begining like normal node application.
2.moleculer cli- to setup realtime project with all artifacts.

npm install moleculer


Core concepts in Molecular:
..........................

Service
 A service is a simple JavaScript module containing some part of a complex application. 
 A service represents a biz logic in your application.

Service Broker : == Spring Container
 Service Broker is the heart of Moleculer.

It is responsible for management and communication between services (local and remote). 
Each node must have an instance of Service Broker.

"Service Broker is one single Node instance - Node runtime"


		         Service1 -- Service 2 Service N
                                     |
                    		 --------------
				 Service Broker
				     |
                                 Node Runtime



Use case : how to create Service broker and start

//Get ServiceBroker function(class)
const { ServiceBroker } = require('moleculer');

//Create Service Broker object.
const broker = new ServiceBroker();


How write service , how to use that service?

 Service is program, which has biz logic

Service is created 

broker.createService(serivice definition)

service definition is literal object which contains all service configuration.

Service configuration is other wise called "Service schema".


How to invoke/call Service methods?

There are many ways

1.By using broker.start method  and broker.call method
2.By using  REPL cli
3.By using another service => Service to Service calls


//get Service Broker ;

const { ServiceBroker } = require('moleculer');

//create Service Broker instance;
const broker = new ServiceBroker();

//create helloworld service

broker.createService({
    name: 'helloworld',
    actions: {
        //biz methods
        sayHello() {
            return 'Hello Moleculer'
        }

    }
});
//start service broker;

function startApp() {

    //start the broker
    broker.start()
        .then(res => {
            console.log('broker is ready');
            broker.call('helloworld.sayHello')
                .then(response => {
                    console.log('Response  is ready')
                    console.log(response);
                })
                .catch(err => { });
        })
        .catch(err => { });
}
//startApp();
async function initApp() {
    try {
        await broker.start();
        const response = await broker.call('helloworld.sayHello');
        console.log(response);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Use case 2 ; multi methods:
//get Service Broker ;

const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();


broker.createService({
    name: 'greeterservice',
    actions: {
        //biz methods
        sayHello() {
            return 'Hello Moleculer'
        },
        sayHai() {
            return 'Hai Moleculer'
        },
        sayGreet() {
            return 'Greet Moleculer'
        }

    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        const hello = await broker.call('greeterservice.sayHello');
        const hai = await broker.call('greeterservice.sayHai');
        const greet = await broker.call('greeterservice.sayGreet');
        console.log(hello,hai,greet);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Use case 3 ; multi service;
............................


//get Service Broker ;

const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

broker.createService({
    name: 'helloservice',
    actions: {
        //biz methods
        sayHello() {
            return 'Hello Moleculer'
        }

    }
});

broker.createService({
    name: 'haiservice',
    actions: {
        //biz methods
        sayHai() {
            return 'Hai Moleculer'
        }

    }
});

broker.createService({
    name: 'greeterservice',
    actions: {
        //biz methods
        sayGreet() {
            return 'Greet Moleculer'
        }

    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        const hello = await broker.call('helloservice.sayHello');
        const hai = await broker.call('haiservice.sayHai');
        const greet = await broker.call('greeterservice.sayGreet');
        console.log(hello,hai,greet);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();
//////////////////////////////////////////////////////////////////////////////////////////////////////

Use case 4 ;passing parameters to service methods

How to pass parameter to Service?

Any Service can take parameter, which type could be any thing: number,string,boolean,array,
object...

Syntax:

broker.call("serviceName.method",{p1:value1,p2:value2,pn:valueN})

Note: parameters must be encapsulated into an literal object



How to read args from the service Method?

Parameters are stored inside special object called "Context"

Context Object:

1.Similar to Broker Object
2.It has all capacity of Broker object
3.Context object is used inside service definitions , where ever you require broker
  Object reference.

context object already created, and its refernce is avaiable inside "Service method" as 
args.




//get Service Broker ;

const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

broker.createService({
    name: 'greeterservice',
    actions: {
        //ctx is variable points "Context Object"
        sayHello(ctx) {
            console.log(ctx.params);
            const { message, whom } = ctx.params;
            //return `${ctx.params.message} ${ctx.params.whom}`
            return `${message} ${whom}`
        }

    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        const hello = await broker.call('greeterservice.sayHello', { message: 'Hello', whom: 'Moleculer' });
        console.log(hello);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();

//////////////////////////////////////////////////////////////////////////////////////////////////////

Use case 6 ; Parameter validation; defining extra method behaviours(like do y want to enable caching for that method)..
..............................
moleculer provides validation framework for validating incoming parameters.

const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

//parameter validation;

broker.createService({
    name: 'adderservice',
    actions: {
        //inject extra behaviour for method add
        add: {
            //validation feature
            params: {
                a: "number",
                b: "number"
            },
            //biz logic via handler method
            handler(ctx) {
                const { a, b } = ctx.params;
                return a + b;
            }
        }
    }
});



async function initApp() {
    try {
        await broker.start();
        const addResult = await broker.call('adderservice.add', { a: 10, b: 20 });
        //validation error message call
        //const addResult = await broker.call('adderservice.add', { a: "10", b: 20 });
        console.log(addResult);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();

////////////////////////////////////////////////////////////////////////////////////////////////////////

Use case 7: How to version services

/api/v1/resource
/api/v2/resource

const { ServiceBroker } = require('moleculer');
const broker = new ServiceBroker();

broker.createService({
    name: 'helloworld',
    version: 1,
    actions: {
        //biz methods
        sayHello() {
            return 'Hello Moleculer -v1'
        }

    }
});
broker.createService({
    name: 'helloworld',
    version: 2,
    actions: {
        //biz methods
        sayHello() {
            return 'Hello Moleculer -v2'
        }

    }
});

async function initApp() {
    try {
        await broker.start();
        //calling versioning service v1.service.actionname
        let response;
        response = await broker.call('v1.helloworld.sayHello');
        console.log(response);
        response = await broker.call('v2.helloworld.sayHello');
        console.log(response);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();
////////////////////////////////////////////////////////////////////////////////////////////////////////

Methods;

 are used to represent a logic .

Types of methods

-public methods
  public methods are accessiable outside service, other services / other apis can call.
 public methods are defined inside "action" definition.

-private methods
 private methods are private to that service only.
 cant be accessed outside
 private methods are very usefull for breaking complex biz logic,
 private methods can be called inside public method for result


Use case 8; private methods

const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

//parameter validation;

broker.createService({
    name: 'calculatorservice',
    actions: {
        //inject extra behaviour for method add
        add: {
            //validation feature
            params: {
                a: "number",
                b: "number"
            },
            //biz logic via handler method
            handler(ctx) {
                const { a, b } = ctx.params;
                return this.add(a, b);
            }
        },
        substract: {
            //validation feature
            params: {
                a: "number",
                b: "number"
            },
            //biz logic via handler method
            handler(ctx) {
                const { a, b } = ctx.params;
                return this.substract(a, b);
            }
        }
    },
    //private methods
    methods: {
        add(a, b) {
            return a + b;
        },
        substract(a, b) {
            return a - b;
        }
    }
});



async function initApp() {
    try {
        await broker.start();
        let result;
        result = await broker.call('calculatorservice.add', { a: 20, b: 10 })
        console.log('Add : ', result);
        result = await broker.call('calculatorservice.substract', { a: 20, b: 10 })
        console.log('Substract : ', result);

    }
    catch (err) {
        console.log(err)
    }
}
initApp();
//////////////////////////////////////////////////////////////////////////////////////////////////////


Service Communication:
.....................

Two or more services can be communicated.

Types of services:

1.local service
2.remote service
3.api service


Use case 9; local services

local service;
  services are created and executed under single service broker

//local service communication
const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

broker.createService({
    name: 'calculatorservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                //call add service;you can use context object
                const { a, b } = ctx.params;
                return ctx.call('addservice.add', { a: a, b: b });
            }

        }
    }
});

//back end service , which does computation in back ground.
broker.createService({
    name: 'addservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                const { a, b } = ctx.params;
                return this.add(a, b)
            }

        }
    },
    methods: {
        add(a, b) {
            return a + b;
        }
    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        const result = await broker.call('calculatorservice.add', { a: 10, b: 20 });
        console.log(result);
    }
    catch (err) {
        console.log(err)
    }
}
initApp();
///////////////////////////////////////////////////////////////////////////////////////////////////////////


By using  REPL cli:

>npm install moleculer-repl --save-dev
.................................................................................................


Use case 10; Remote Services;


 Services are hosted across the nodes(service brokers)


consumer.service.js
//local service communication
const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

broker.createService({
    name: 'calculatorservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                //call add service;you can use context object
                const { a, b } = ctx.params;
                return ctx.call('addservice.add', { a: a, b: b });
            }

        }
    }
});
//start service broker;
async function initApp() {
    try {
        await broker.start();
        await broker.repl()
    }
    catch (err) {
        console.log(err)
    }
}
initApp();

provider.service.js
const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker();

//back end service , which does computation in back ground.
broker.createService({
    name: 'addservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                const { a, b } = ctx.params;
                return this.add(a, b)
            }

        }
    },
    methods: {
        add(a, b) {
            return a + b;
        }
    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        await broker.repl();
        
    }
    catch (err) {
        console.log(err)
    }
}
initApp();

if you start calling, you will get the error 

>> ERROR:
ServiceNotFoundError: Service 'addservice.add' is not found.
    at ServiceBroker.findNextActionEndpoint (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\service-broker.js:1020:13)
    at ServiceBroker.call (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\service-broker.js:1069:26)
    at Context.call (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\context.js:289:23)
    at Service.handler (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\services\consumer.service.js:17:28)
    at C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\utils.js:182:22
    at validateContextParams (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\validators\base.js:72:15)
    at ServiceBroker.timeoutMiddleware (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\middlewares\timeout.js:35:14)
    at ServiceBroker.fallbackMiddleware (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\middlewares\fallback.js:29:11)
    at ServiceBroker.errorHandlerMiddleware (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\middlewares\error-handler.js:14:10)
    at ServiceBroker.call (C:\session\ibm\Sep\nodejs-session\mymicroservice-app\node_modules\moleculer\src\service-broker.js:1084:31)

why this error?

Because services are running in different nodes / service brokers- distributed services

How the nodes can communicate each other?

We need networking infra structure.

Message Brokers:Transporters:

Transporter is an important module if you are running services on multiple nodes. 

Transporter communicates with other nodes. 

It transfers events, calls requests and processes responses …etc. 

If a service runs on multiple instances on different nodes, the requests will be load-balanced among live nodes.



Transpoerts:
............

Built-in transporters

TCP transporter
NATS Transporter
Redis Transporter
MQTT Transporter
AMQP Transporter
Kafka Transporter
NATS Streaming (STAN) Transporter

Service Broker configuration:

let broker =new ServiceBroker();
Broker is created with default configuration.

We can overload the default configuration based on our needs.

let broker =new ServiceBroker({
  key:value
});

steps:

1.start any transporter

eg: nats,redis..

docker run -p 4444:4444 nats -p 4444


2.transporter configuration in service

const broker = new ServiceBroker({
    transporter: "nats://nats.server:4444"
});

3.npm install nats --save

Note if you want any other transporter you have to follow the same steps

steps:

1.start redis server
docker run  -p 6379:6379  redis

2.install
npm install ioredis --save

redis:
transporter: "redis://localhost:6379"

//////////////////////////////////////////////////////////////////////////////////////////////////////


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Registry & Discovery:
....................

1.Service Registry

 It is mini /small database , key-value pair database, in memory database.
 Which has all service,actions,event listeners, nodes information.


Points:
1.Every Broker has in built Service Registry
     Moleculer has built in in memory registry, we can use that registry directly.

2.All services local or remote are registered with service registry as soon you create 
  service
3.Molecular has built in registry called LocalDiscoveryRegistry, which is not using third party registry servers
  like apache zoo keeper,cosule,etcd,eurka....

4.if you want to make other servers as service registry -

    registry: {
        discoverer: "redis://redis-server:6379"
    }  
Dynamic service discovery
1.Local
2.Redis
3.etcd3
4.Customization

//////////////////////////////////////////////////////////////////////////////////////////////////////
Exploring logs of moleculer runtime for service registry information.

[2020-10-01T07:11:06.221Z] INFO  laptop-r2tggfdl-996/REGISTRY: Discoverer: LocalDiscoverer
This log defins type of registry server

[2020-10-01T07:11:06.786Z] INFO  laptop-r2tggfdl-996/REGISTRY: '$node' service is registered.
[2020-10-01T07:11:06.788Z] INFO  laptop-r2tggfdl-996/REGISTRY: 'calculatorservice' service is registered.


How to change service discovery registry server from LocalDiscover?


//local service communication
const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker({
    //nodeID : 'ibmconsumernode',
    transporter: "nats://localhost:4444",
    registry: {
        discoverer: "redis://localhost:6379"
    } 
});

broker.createService({
    name: 'calculatorservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                //call add service;you can use context object
                const { a, b } = ctx.params;
                return ctx.call('addservice.add', { a: a, b: b });
            }

        }
    }
});
//start service broker;
async function initApp() {
    try {
        await broker.start();
        await broker.repl()
    }
    catch (err) {
        console.log(err)
    }
}
initApp();

const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker({
    //nodeID:'ibmprovidernode',
    transporter: "nats://localhost:4444",
    registry: {
        discoverer: "redis://localhost:6379"
    } 
});

//back end service , which does computation in back ground.
broker.createService({
    name: 'addservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                const { a, b } = ctx.params;
                return this.add(a, b)
            }

        }
    },
    methods: {
        add(a, b) {
            return a + b;
        }
    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        await broker.repl();
        
    }
    catch (err) {
        console.log(err)
    }
}
initApp();
//////////////////////////////////////////////////////////////////////////////////////////////////////
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Scalability and High availability ; Load Balancer / fail over
............................................................


Load balancing means , distributing load to different machines in the cluster.

In distributed computing, one server may not be enough to  handle load.

1.Moleculer has several built-in load balancing strategies.

Built-in strategies

 ->RoundRobin strategy
	This strategy selects a node based on round-robin algorithm.
   Refer:https://en.wikipedia.org/wiki/Round-robin_DNS
 ->Random strategy
	This strategy selects a node randomly.
 ->CPU usage-based strategy
	This strategy selects a node which has the lowest CPU usage. Due to the node list can 	be very long, it gets samples and selects the node with the lowest CPU usage from only 	samples instead of the whole node list.

 ->Latency-based strategy
	This strategy selects a node which has the lowest latency, measured by periodic ping commands. Notice that the strategy only ping one of nodes from a single host.


    registry: {
        strategy: "RoundRobin"
    }

Demo:

steps:

1.start consumer service

2.start publisher service 2 instances.

3.query publisher from consumer , and see which instance is giving result.



updated code from the provier side
const { ServiceBroker } = require('moleculer');

const broker = new ServiceBroker({
    //nodeID:'ibmprovidernode',
    transporter: "nats://localhost:4444",
    registry: {
        discoverer: "redis://localhost:6379",
        strategy: "RoundRobin"

    },
  

});

//back end service , which does computation in back ground.
broker.createService({
    name: 'addservice',
    actions: {
        add: {
            params: {
                a: "number",
                b: "number"
            },
            handler(ctx) {
                const { a, b } = ctx.params;
                return `${this.add(a, b) } is coming ${broker.nodeID}`
            }

        }
    },
    methods: {
        add(a, b) {
            return a + b;
        }
    }
});

//start service broker;
async function initApp() {
    try {
        await broker.start();
        await broker.repl();
        
    }
    catch (err) {
        console.log(err)
    }
}
initApp();
///////////////////////////////////////////////////////////////////////////////////////////////////////

Service inheritance:

Objective:

 lets say i have a service having more methods, that i dont want to give in a service
 i have service , that service apis , i want to reuse in service apis

Service inheritance comes into place.

In molecular , a service can inherit many services - multi level, for multi level, molcular uses
a concept called "mixins".

Use case:
1.if you write any REST Controller.
2.if you write database operations inside your service.

////////////////////////////////////////////////////////////////////////////////////////////////////////

Parent service must be placed in a separate file, but that be same part of broker object




parent.service.js

module.exports = {
    name: 'hello',
    actions: {
        //define biz api of that service
        sayHello() {
            return 'Hello,Molecular'
        }
    }
};


child

const { ServiceBroker } = require('moleculer');
const hello = require('./parent.service');
const { log } = console;
const broker = new ServiceBroker();


broker.createService({
    name: 'greeter',
    mixins: [hello],
    actions: {
        sayGreet:{
            handler(){
                return 'Greet';
            }
        }
    }
});


async function init() {
    try {
        await broker.start();
        let response;
        response = await broker.call('greeter.sayHello')
        log(`${response}`)
        response = await broker.call('greeter.sayGreet')
        log(`${response}`)

    }
    catch (e) {
        log(e);
    }
}
init();
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Event Driven Architecture:

Broker has a built-in event bus to support Event-driven architecture and to send events to local and remote services.

//how to register events?

events: {
        "user.created"(ctx) {
            console.log("Payload:", ctx.params);
            console.log("Sender:", ctx.nodeID);
            console.log("Metadata:", ctx.meta);
            console.log("The called event name:", ctx.eventName);

          );
        }
    }

how to send events

send to only consumer.

  ctx.emit("user.created", { user: ctx.params.user });
  broker.emit("user.created", { user: ctx.params.user });


 send to mulitple consumers
  ctx.broadcast("user.created",{user:ctx.params.user});


const { ServiceBroker } = require('moleculer');
const { log } = console;
const broker = new ServiceBroker();

//Listener service
broker.createService({
    name: 'reportlistner',
    events: {
        "user.created"(ctx) {
            console.log("User created:", ctx.params);
        }
    }
});

broker.createService({
    name: 'reportsender',
    actions: {
        sendReport(ctx) {
            let user = {
                id: 1,
                name: 'subramanian'
            }
            ctx.emit("user.created", { entity: user });
            return `Report has been sent`
        }
    }
});

async function init() {
    try {
        await broker.start();
        let response;
        response = await broker.call('reportsender.sendReport');
        log(response);

    }
    catch (e) {
        log(e);
    }
}
init();
///
////////////////////////////////////////////////////////////////////////////////////////////////////////


Molecular Service Types:


1.Local Service
2.Remote Service

.............

1.back end service
  service which is having application logic.

2.front end service /api gate way service.
  Service which exposes apis are as "Rest End points".


API GATE Implementation:
Molecular provides lot of modules 

1.moleculer-web

moleculer-web is official gatway module, which is built on express.js


Steps:

1.npm install moleculer-web --save

2.Since  moleculer-web is separate module, you have create your own service, convert that service
  into gatewayservice





Rest Service:

Simple:

const { ServiceBroker } = require('moleculer');
let ApiService = require("moleculer-web");

const { log } = console;

const broker = new ServiceBroker();


broker.createService({
    name:'apigateway',
    mixins:[ApiService],
    settings: {
        routes:[{
            path:"/api",
            whitelist: [
                // Access any actions in 'hello' service
                "hello.*",
            ]
        }]
    }
});


broker.createService({
    name: 'hello',
    actions: {
        //define biz api of that service
        sayHello() {
            return 'Hello,Molecular'
        }
    }
});

async function init() {
    try {
        await broker.start();
        }
    catch (e) {
        log(e);
    }
}
init();

url mapping;
http://localhost:3000/api/hello/sayHello



Aliases:
.........

You can use alias names instead of action names. You can also specify the method. Otherwise it will handle every method types.

http://localhost:3000/api/hello/

broker.createService({
    name:'apigateway',
    mixins:[ApiService],
    settings: {
        routes:[{
            path:"/api",
            aliases: {
               "hello": "hello.sayHello"
            }
        }]
    }
});


/////////////////////////////////////////////////////////////////////////////////////////////////

METHOD Name mapping ; by default GET METHOD.
.........................................


broker.createService({
    mixins: [ApiService],

    settings: {
        routes: [{
            aliases: {
                "GET users": "users.list",
                "GET users/:id": "users.get",
                "POST users": "users.create",
                "PUT users/:id": "users.update",
                "DELETE users/:id": "users.remove"
            }
        }]
    }
});

Dynamic path; path parameter ; /:id
/api/hello/1

const { ServiceBroker } = require('moleculer');
const ApiService = require("moleculer-web");


const broker = new ServiceBroker();

// broker.createService({
//     name: 'apigateway',
//     mixins: [ApiService],
//     settings: {
//         routes: [{
//             path: "/api",
//             whitelist: [
//                 // Access any actions in 'hello' service : url mapping policy
//                 "hello.*",
//             ]
//         }]
//     }
// })

//alise mapping
// broker.createService({
//     name:'apigateway',
//     mixins:[ApiService],
//     settings: {
//         routes:[{
//             path:"/api",
//             aliases: {
//                "hello": "hello.sayHello"
//             }
//         }]
//     }
// });


broker.createService({
    name:'apigateway',
    mixins:[ApiService],
    settings: {
        routes:[{
            path:"/api",
            aliases: {
               "GET hello": "hello.sayHello",
                  // The `name` comes from named param. 
                // You can access it with `ctx.params.name` in action
               "GET hello/:name": "hello.sayHelloByName"
            }
        }]
    }
});


broker.createService({
    name: 'hello',
    actions: {
        //define biz api of that service
        sayHello() {
            return 'Hello,Molecular'
        },
        
        sayHelloByName(ctx) {
            return `Hello ${ctx.params.name}`
        }
    }
});
async function init() {
    try {
        await broker.start();
        }
    catch (e) {
        log(e);
    }
}
init();
///////////////////////////////////////////////////////////////////////////////////////////////////////

For REST routes you can also use this simple shorthand alias:

broker.createService({
    mixins: [ApiService],

    settings: {
        path:'/api',
        routes: [{
            aliases: {
                "REST users": "users"
            }
        }]
    }
});
To use this shorthand alias, create a service which has list, get, create, update and remove actions.



broker.createService({
    name: 'users',
    actions: {
      list: {},
      get:{}
      create :{},
      update:{},
      remove:{}
    }
});

///////////////////////////////////////////////////////////////////////////////////////////////////////

Data base integreation:
......................

Moleculer provides orm like implemenation.
Auto curd generations

Database Adapters

Features:

default CRUD actions
cached actions
pagination support
pluggable adapter (NeDB is the default memory adapter for testing & prototyping)
official adapters for MongoDB, PostgreSQL, SQLite, MySQL, MSSQL.
fields filtering
populating
encode/decode IDs
entity lifecycle events for notifications



$ npm install moleculer-db --save

  Which is nedb adpater , use full testing and prototyping.

if you want to change database, you can.

npm i moleculer-db-adapter-mongo --save

"use strict";

const { ServiceBroker } = require("moleculer");
const DbService = require("moleculer-db");
const MongoDBAdapter = require("moleculer-db-adapter-mongo");


const broker = new ServiceBroker();
// Create a DB service for `user` entities
broker.createService({
    name: "users",

    // Mixin DB service into (current) 'users' service
    mixins: [DbService],
    adapter: new MongoDBAdapter("mongodb://localhost/moleculer-demo"),
    collection: "users",
    settings: {
        idField: 'id',
        fields: ["id", "username", "name"],
        entityValidator: {
            username: "string"
        }
    },

    afterConnected() {
        // Seed the DB with ˙this.create`
    }
});
async function initApp() {
    await broker.start()
    for (let i = 1; i <= 10; i++) {
        await broker.call("users.create", {
            username: "john-" + i,
            name: "John Doe -" + i,
            status: 1,
            id: i
        })
    }
    const users = await broker.call("users.find");
    console.log('users', users);
    const updateduser = await broker.call("users.update", { id: 1, name: "Subramanian" });
    console.log('updated', updateduser);
    const removedusr = await broker.call("users.remove", { id: 2 });
    //no of records affected;
    console.log('Removed User ', removedusr)
    
    console.log(await broker.call("users.find"));

}
initApp();
///////////////////////////////////////////////////////////////////////////////////////////////////////

Moleculer Runner
Moleculer Runner is a helper script that helps you running Moleculer projects. With it you don’t need to create a ServiceBroker instance with options. Instead you can create a moleculer.config.js file in the root of repo with broker options. Then simply call the moleculer-runner in NPM script and it will automatically load the configuration file, create the broker and load the services. Alternatively, you can declare your configuration as environment variables.


scalability - no instances 
we need to run in back ground
container integration and oracheration - docker,docker-compose
modularaztion
REST endpoints-api gate way
Database integration
Tracing and meterics integration.
......

Soultion ; tool;

npm i -g moleculer-cli


Modularaztion ;

separate service files

one service broker with all configuration;
 -service broker configuration is represented in moleculer.config.js

here broker instance is hidden, moleculer runner , which feeds defion to broker

////////////////////////////////////////////////////////////////////////////////////////////////////////

TODO App using Moleculer;

you can use REST End points
you can use db.
CURD operations.

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

















